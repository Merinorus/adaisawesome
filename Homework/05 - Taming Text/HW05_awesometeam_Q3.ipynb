{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the models.ldamodel module from the gensim library, run topic modeling over the corpus. Explore different numbers of topics (varying from 5 to 50), and settle for the parameter which returns topics that you consider to be meaningful at first sight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding a compromise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to do topic modeling over all the mails. In other words, we have to find recurrent topic or themes that may appear in the conversations.\n",
    "They are several way to analyse the mails content, starting by these two \"naive\" ways:\n",
    "- put all the extrated mails in only one document\n",
    "- put each extracted mail in a separate document\n",
    "\n",
    "But both of these ways have major drawbacks:\n",
    "- doing topic modelling on a single document would show the most frequent words, so the result should be the same as if we wanted to make a word cloud\n",
    "- a lot of mail are very small, a few words sometimes, so doing topic analysis here would not be extremely meaningful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to find a compromise: make multiple documents, each of them long enough to be analysed.\n",
    "One of the best options would be create the entire conversations with the mail history, so we can extract main topic from each conversation. While it makes sense, it's actually pretty time-consuming to obtain the conversations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do here is simply put each mail in a separate document, excluding mails that are too small to be analysed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re # regular expressions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We reuse data from question 1 that already did a lot of cleaning operations !\n",
    "emails_cleaned = pd.read_pickle(\"ilovepickefiles_stemming.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TokenizedText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[chris, steven]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[cairo, condemn, final]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[meet, right, wing, extremist, behind, anti, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[anti, muslim, film, director, hide, follow, l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       TokenizedText\n",
       "0                                                 []\n",
       "1                                    [chris, steven]\n",
       "2                            [cairo, condemn, final]\n",
       "3  [meet, right, wing, extremist, behind, anti, m...\n",
       "4  [anti, muslim, film, director, hide, follow, l..."
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the topic modeling, we still see some words that don't really fit in any topic (eg: would) so we remove some of them intentionally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ignore_list = ['00', '10', '15', '30', 'also', 'would']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for mail in emails_cleaned.TokenizedText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We put all the mails in a text table in order to prepare the corpus to be analysed. We exclude mails that are too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of mail: 13002\n",
      "Mails with at least 2 tokens represent 71.9350869097 % of the total.\n",
      "Mails with at least 3 tokens represent 56.8527918782 % of the total.\n",
      "Mails with at least 4 tokens represent 47.0389170897 % of the total.\n",
      "Mails with at least 5 tokens represent 40.1169050915 % of the total.\n",
      "Mails with at least 6 tokens represent 35.0176895862 % of the total.\n",
      "Mails with at least 10 tokens represent 21.8120289186 % of the total.\n",
      "Mails with at least 15 tokens represent 15.3976311337 % of the total.\n",
      "Mails with at least 20 tokens represent 11.8289493924 % of the total.\n",
      "Mails with at least 50 tokens represent 5.4606983541 % of the total.\n"
     ]
    }
   ],
   "source": [
    "min_mail_size = [2, 3, 4, 5, 6, 10, 15, 20, 50];\n",
    "print(\"Total number of mail: \" + str(emails_cleaned.size))\n",
    "for i in min_mail_size:\n",
    "    text = []\n",
    "    for mail in emails_cleaned.TokenizedText:\n",
    "        if (len(mail) >= i):\n",
    "            text.append(mail)\n",
    "    ratio = len(text) / emails_cleaned.size * 100\n",
    "    print(\"Mails with at least \" + str(i) + \" tokens represent \" + str(ratio).zfill(4) + \" % of the total.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose keep mails with at least 5 tokens: we can have sentences that might make sense, while keeping 40 % of the mails. This is about 5000 mails, so we should be able to extract some topics from them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MIN_MAIL_SIZE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "for mail in emails_cleaned.TokenizedText:\n",
    "    # Take only mails that are long enough\n",
    "    if (len(mail) >= MIN_MAIL_SIZE):\n",
    "        # Remove unwanted words\n",
    "        mail_filtered = mail\n",
    "        for word in mail_filtered:\n",
    "            if word in ignore_list:\n",
    "                mail_filtered.remove(word)\n",
    "        text.append(mail_filtered)\n",
    "ratio = len(text) / emails_cleaned.size * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we convert all the mails' words in numbers, each number corresponding to a word. In other words, we convert our table of mail in a corpus, so we will be able to do topic modeling on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_dictionary = corpora.Dictionary(text)\n",
    "corpus = [text_dictionary.doc2bow(t) for t in text] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, time to do the modeling. We will play with the topic number in order to have a consistent result.\n",
    "Let's try with different numbers. First 5, then 10, 25 and finally 50 topics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_topics(lda_model):\n",
    "    for i in range(lda_model.num_topics):\n",
    "        topic_words = [word for word, _ in lda_model.show_topic(i, topn = 15)]\n",
    "        print('Topic ' + str(i+1) + ': ', end = ' ')\n",
    "        for word in topic_words:\n",
    "            print(word, end = ' ')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:  state call said offic time secretari presid want work 2009 clinton depart hous meet like \n",
      "Topic 2:  state work depart said obama govern presid peopl right offic like american secur foreign secretari \n",
      "Topic 3:  state secretari offic time meet depart work 2010 presid govern year hous need obama nation \n",
      "Topic 4:  state obama call presid secretari year hous meet work time american peopl think said want \n",
      "Topic 5:  state right 2010 parti obama year time like american presid call foreign meet issu work \n"
     ]
    }
   ],
   "source": [
    "lda_model = models.LdaMulticore(corpus, id2word = text_dictionary, num_topics = 5)\n",
    "show_topics(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:  state obama presid time secretari call offic american meet said first talk secur hous depart \n",
      "Topic 2:  state said obama work presid american like depart secretari govern nation 2010 time polici 2009 \n",
      "Topic 3:  state work want time nation israel call need 2010 meet secretari like obama year report \n",
      "Topic 4:  state hous call american time said depart offic secretari presid peopl work govern meet obama \n",
      "Topic 5:  state obama presid work like offic said senat 2009 hous right govern time year need \n",
      "Topic 6:  state american like govern year time 2009 last work want presid think 2010 women know \n",
      "Topic 7:  call state right said obama secretari work presid 2010 time want need today know like \n",
      "Topic 8:  state depart secretari offic said time 2009 nation meet polit rout privat peopl hous presid \n",
      "Topic 9:  state secretari depart work offic clinton hous meet time like presid said 2009 2010 obama \n",
      "Topic 10:  state offic secretari depart time meet senat room said issu work obama presid 2010 year \n"
     ]
    }
   ],
   "source": [
    "lda_model = models.LdaMulticore(corpus, id2word = text_dictionary, num_topics = 10)\n",
    "show_topics(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:  state need secretari peopl meet presid american govern said time last obama offic 2015 depart \n",
      "Topic 2:  state call work time obama secur year like depart talk want meet israel think 2009 \n",
      "Topic 3:  state israel call secur work talk 2009 obama polici said time nation right american peac \n",
      "Topic 4:  state presid obama 2010 secretari offic meet american polit hous time said call percent nation \n",
      "Topic 5:  state call obama make meet time cheryl 2009 depart israel american mill presid 2015 secretari \n",
      "Topic 6:  call said state work time want need talk peopl think polit presid today hous govern \n",
      "Topic 7:  offic depart state meet secretari call room work time nation said arriv offici confer presid \n",
      "Topic 8:  offic state call secretari meet 2010 time said american depart presid democrat like republican parti \n",
      "Topic 9:  secretari offic depart state time call arriv meet rout hous room washington privat white nation \n",
      "Topic 10:  obama senat democrat state presid right polit republican like think nation parti even vote year \n",
      "Topic 11:  state clinton hous time 2009 presid said depart work report 2010 want meet obama 2015 \n",
      "Topic 12:  secretari offic depart state room meet call time 45 arriv hous resid privat rout confer \n",
      "Topic 13:  state call time presid offic american obama said secretari like issu work depart govern meet \n",
      "Topic 14:  call talk time state meet obama want district said today like right hous foreign work \n",
      "Topic 15:  state time call obama like secretari presid year 2009 american 2010 percent said want republican \n",
      "Topic 16:  state 2010 time like work call back american year hous think obama want peopl depart \n",
      "Topic 17:  state secretari 2010 time 2009 peopl call work huma unit clinton like presid assist lona \n",
      "Topic 18:  state want back secretari call meet presid hous depart women govern said think year peopl \n",
      "Topic 19:  state obama like time american call meet know presid said could govern year need 2009 \n",
      "Topic 20:  state 2009 2010 obama time year govern thank work presid right know first huma group \n",
      "Topic 21:  state work time said 2009 presid women obama first call govern know 2010 polit today \n",
      "Topic 22:  state said year obama hous presid clinton work govern first call like democrat secur support \n",
      "Topic 23:  state clinton work right govern senat vote depart said obama 2009 make want secretari presid \n",
      "Topic 24:  state women work call 2009 like obama said govern peopl think support make meet discuss \n",
      "Topic 25:  state hous american 2015 work year depart secretari offic 2010 obama presid report time said \n"
     ]
    }
   ],
   "source": [
    "lda_model = models.LdaMulticore(corpus, id2word = text_dictionary, num_topics = 25)\n",
    "show_topics(lda_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:  obama american clinton presid back democrat think last right like peopl time offici state polit \n",
      "Topic 2:  secretari state offic depart time meet obama presid call hous clinton talk govern white secur \n",
      "Topic 3:  state obama hous today said senat israel vote presid work 2010 offic meet polit iran \n",
      "Topic 4:  state secretari said like 2010 offic presid time call work room depart good hous year \n",
      "Topic 5:  call state like american meet work time right email 2009 think korea north year want \n",
      "Topic 6:  state said presid secretari clinton peopl time american work obama first year like call want \n",
      "Topic 7:  state work percent presid call obama republican right said american secretari democrat time like come \n",
      "Topic 8:  state said call hous presid time foreign today govern work know want leader unit first \n",
      "Topic 9:  time israel work polici said take talk state need american right make parti call want \n",
      "Topic 10:  state secretari offic depart meet 2010 room work hous presid time like obama secur call \n",
      "Topic 11:  state call 2015 speech hous 2010 last think offic thank said know work case draft \n",
      "Topic 12:  state obama time secretari polici right presid women 2010 said like clinton year meet parti \n",
      "Topic 13:  call presid polit obama state secretari govern 2010 like could work year peac know american \n",
      "Topic 14:  state work presid obama women peopl polici nation american clinton want world polit govern countri \n",
      "Topic 15:  state depart offic secretari arriv room rout meet time 2015 45 airport nation hous privat \n",
      "Topic 16:  state work time said want call year obama know peopl 2009 presid talk like parti \n",
      "Topic 17:  said state presid parti 2009 support like need govern year hous back republican democrat obama \n",
      "Topic 18:  state american call said work support time clinton peopl want govern secur year nation world \n",
      "Topic 19:  2010 state obama american time think right mill cheryl afghanistan polici like work march presid \n",
      "Topic 20:  state call obama work palestinian year said presid israel parti 2009 2010 make peopl hous \n",
      "Topic 21:  state obama year said american like presid time nation 2010 secretari group countri hous issu \n",
      "Topic 22:  state work meet said depart could want american obama govern call know like come presid \n",
      "Topic 23:  state said time need want work 2010 call secur presid obama talk peopl like 2009 \n",
      "Topic 24:  state call like 2010 govern obama said today parti polit want time know help democrat \n",
      "Topic 25:  state peopl want obama presid said nation 2010 time date 2015 take hous secur need \n",
      "Topic 26:  state call 2009 mill cheryl time work year millscd govern isra want 2010 obama need \n",
      "Topic 27:  state parti time call labour right said need govern elect 2009 want thursday know work \n",
      "Topic 28:  call state want 2009 cheryl mill obama thank presid like right millscd american govern friday \n",
      "Topic 29:  state time meet said secretari 2009 presid obama call polit like work offic could hous \n",
      "Topic 30:  work state time like israel washington peopl presid obama american want today right call think \n",
      "Topic 31:  state secretari offic call depart time meet minist room hous democrat foreign obama privat 45 \n",
      "Topic 32:  state time work 2009 senat call presid govern secretari peopl said clinton 2010 talk start \n",
      "Topic 33:  call work tomorrow state 2009 offic make like last time want meet back right year \n",
      "Topic 34:  state secretari said obama 2009 offic presid 2010 meet govern clinton time depart percent know \n",
      "Topic 35:  state depart hous 2015 offic secretari call 2010 case date inform produc benghazi 13 2009 \n",
      "Topic 36:  call china state want work report hous offic obama world could nation year offici said \n",
      "Topic 37:  state women obama nation polici year presid issu work need american unit right govern clinton \n",
      "Topic 38:  state work need time presid american year meet call right obama make secur tomorrow peopl \n",
      "Topic 39:  state 2009 work said time polit obama presid vote secretari year secur meet govern call \n",
      "Topic 40:  obama state call senat presid time israel govern hous like need nation peopl last made \n",
      "Topic 41:  state 2010 group need want 2009 discuss thursday call said right senat elect today email \n",
      "Topic 42:  state obama presid call depart 2010 govern said american need percent meet right work vote \n",
      "Topic 43:  secretari offic meet room call depart privat minist rout arriv resid 45 talk support state \n",
      "Topic 44:  state call secretari time today meet obama said like presid know peopl mcchrystal 2010 afghanistan \n",
      "Topic 45:  call presid time state report american obama year 2010 offic offici israel talk polit 2009 \n",
      "Topic 46:  said work obama presid state afghanistan secur like american countri time afghan peopl support back \n",
      "Topic 47:  year like work call said state could know 2010 make want peopl obama 2009 american \n",
      "Topic 48:  offic secretari state depart meet call arriv senat presid know talk nation time rout want \n",
      "Topic 49:  state meet time presid clinton secretari work hous obama senat think talk 2010 said white \n",
      "Topic 50:  call state presid time issu support polici year clinton obama said work like american want \n"
     ]
    }
   ],
   "source": [
    "lda_model = models.LdaMulticore(corpus, id2word = text_dictionary, num_topics = 50)\n",
    "show_topics(lda_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First to note, there is some unwanted word cropping (\"secretariat\" becomes \"secretari\"), but it is still readable and shouldn't give totally different results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal was to group words such as they relate to the same topic. The results are not concluding: regardless of the number of topic, the same words always reappear: \"obama\", \"state\", \"secretariat\", \"call\"... It's difficult to put a different name on a lot of topic, because they all look alike a lot.\n",
    "For sure, we can tell an \"administrative\" topic is recurrent: state, secretariat, call, obama, office... The result isn't so exciting !"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
